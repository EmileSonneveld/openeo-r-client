---
title: "Getting Started"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{getting_started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# openEO Project

The openEO concept thrives in context of an ever increasing amount gathered EO data which leads to problems in terms of managing the amount of data and more importantly processing this amount of data in a researchers or companies analysis. The core idea was to provide open-source tools to interact with back-end providers via an open API with predefined set of processes. Those processes are intended to manipulate the underlying multidimensional data cubes, which works as a data abstraction layer. The back-end provider offers in this case the EO data and the processing infrastructure and end-users provide the code to drive their analysis. Therefore different client software comes in handy to aid users in doing so. There are currently openEO clients for Python, JavaScript (web based), R and QGIS.

I know this is scratches only the surface of openEO, so if you want to dive deeper you can use the [openEOs official web page](https://openeo.org) as a starting point or you get more involved in the various projects at [Github](https://github.com/Open-EO).

# openEO R client

As part of openEOs product range this client was developed to address the R user community in order to give them access to openEO and to blend the openEO concept into R and it's commonly used IDE RStudio.

## Package Goals and General Architecture

The openEO architecture is simply client-server based. The clients communicate with the back-ends by static functions for exploring server capabilities, data sets, processes or visualization services (WMS,WFS,WCS) and for managing the calculation on the back-end. Then there is also a degree of freedom regarding the tools / processes provided by the back-end. Usually openEO back-ends adopt to a certain degree the [predefined processes](https://processes.openeo.org/1.0.0/) that aim to define set of common processes for working with multidimensional data cubes. On top of that provider might offer additional processes to either boost their performance or ease usability. 
When we talk about client-server based processing, this means basically that no processing is done in this package, but it will delegate the processing to the back-end and ease the process of creating your analysis workflow by offering a familiar developing environment in R and RStudio. 

## Funding Acknowledgement

The authors acknowledge the financial support to have developed this package during the H2020 project "openEO" (Oct 2017 to Sept 2020) by the European Union, funded under call EO-2-2017: EO Big Data Shift, under grant number 776242. We also acknowledge the financial support received from ESA for the project "R4openEO" (Sept 2021 to Sept 2022). 

Further more openEO was improved and operationalized by ESA funding in the project "openEO Platform" (Sept 2020 to Sept 2022)

## Disclaimer
This software is free of charge. You can use it, distribute it and also improve it under the Apache2 license. In openEO exploration of services and data is also free in most cases. You can even start developing your analysis with the processes provided by the back-end. 
However storing EO data and providing processing capabilities costs money. So openEO providers might charge money for using their infrastructure. Please inform yourselves about eventual costs.
The examples in this vignette are created with the openEO implementation for Google Earth Engine (GEE). Provided processes and data sets will vary among different platform providers, this means that you might not in every case can copy and paste the examples given here. This vignette serves the purpose to explain how to interact with this package in order to execute your analysis.
Again, would like to stress out that the heavy lifting will be done by server back-ends and this package just offers the functions to interact with the back-end in a "mostly" R familiar way. Here and there will be some quirks that are due to the generic implementation of dynamically parsed collections and pre defined processes for any openEO back-end. However the "quirk" will be that you might call processes that are registered at an R6 object like you would call named fields in a list (see `processes()` in "Executing and storing of user-defined processes").
Also the examples in this vignette will be reproducible, but it will not show any results in the vignette. This is due to the interactive part, when dealing with remote platforms - you will need access to them and we cannot share the credentials publicly without explicit consent. The vignette shall guide you, how to perform certain actions in openEO by providing code examples.

## Registration

As mentioned before provider might charge money for accessing their infrastructure and hence you would need to [sign up with EGI](https://docs.egi.eu/documentation/333/users/check-in/signup/) first and then [enroll with openEO Platform](https://openeo.cloud/). This setup is also targeted for the long run (support of more recent openEO API versions). 
For a slightly older version of the API (v1.0.0) you can also use the Google Earth Engine driver with limited capabilities. This system was developed and set up during the H2020 openEO project and you can still access it with the link and credentials provided at the [openeo-earthengine-driver project on Github](https://github.com/Open-EO/openeo-earthengine-driver) section "Demo".

## Connecting to backend

```{r, eval=FALSE }
library(openeo)

url = "https://earthengine.openeo.org"

con = connect(host=url)
```
```{r, eval=FALSE}
capabilities()
```

As you can see, you can either omit the the connection or you state it explicitly via the parameter `con`. All static function that are designed to interact with any openEO back-end will have the connections parameter where you would be able to state the designated back-end connection. If you omit it, R tries to get the most recently connected connection. If you want to change the active connection and don't want to pass the connection to every single interaction function then you can set an already defined connection with `active_connection()`.

## Exploration of data, services and processes

As already mentioned the exploratory functions do not need a registration or sign in and are free of costs. Typical use cases are that you might want to know which collections and which processes are available, as well as which file formats are available for export and which web services for integration in GIS or web apps.

With list_* functions you will get overviews of the elements. Jobs, Services and process graphs are bound to a user and require a authentication. To get more detailed information on those objects, you can use describe_* with their respective ID.

Objects stated in the list object and objects returned as detailed information have the same class, but in the list view some information is hidden. They are treated and printed in the same way.

List objects are always printed as data.frame or tibble. This does not mean, that they are. Those are S3 objects with dedicated `print()` and `as.data.frame()` methods. 

Here are some examples on the collections:

```{r, eval=FALSE}
list_collections()
```


```{r, eval=FALSE}
colls = list_collections()
class(colls)
```

```{r, eval=FALSE}
str(colls$`COPERNICUS/S2`)
```

As in the example before, you are advised to use auto-completion - meaning get an object list like the collections or file formats and use a particular entry via its name. Those lists are very similar to named lists.

```{r, paged.print = FALSE, eval=FALSE}
describe_collection(collection = colls$`COPERNICUS/S2`)
```

Similarly the processes are handled. With `list_processes()` you will get a list of process objects which are visualized via a dedicated `print()` method. The processes obtained here, are just for information purposes. For process graph / workflow creation we will use `processes()`, which creates process collection that contains parametrized functions.

```{r, paged.print=FALSE, eval=FALSE}
process_list = list_processes()

process_list[1:3]
```
In the example above you will print the basic information about the processes to the console. If you want to have a nicer visualization in HTML of the process, you can use `process_viewer()`. Simply pass the 

Again, you can access particular objects by their ID.

```{r, paged.print = FALSE, eval=FALSE}
process_list$`if`
```

```{r, paged.print = FALSE, eval=FALSE}
process_list$`sum`
```


Similarly file formats and service types can be obtained and visualized this way. On a side note, you can also use those objects, when assigning the file format in the openEO process for `save_results` or the service type, when creating a particular web service.

```{r, eval=FALSE}
formats = list_file_formats()
class(formats)
```

```{r, paged.print = FALSE, eval=FALSE}
formats
```

```{r, paged.print=FALSE, eval=FALSE}
formats$output$PNG
```

```{r, eval=FALSE}
class(formats$output$PNG)
```

For formats, we have to distinguish supported input and output formats. Output formats are used when serializing results and input formats are used when aggregating data via polygon, creating a mask from a geometry or potentially uploading a raster image as mask.

```{r, paged.print=FALSE, eval=FALSE}
service_types = list_service_types()
service_types
```


## User-defined process

## Login

```{r, eval=FALSE}
user = ""
pwd = ""

login(user = user,password = pwd,login_type = "basic")
```


## User data


As a registered user, you will have a file space / workspace to upload data to, as well as a list of created, ongoing and completed jobs and services, and to access your account data, where you view the credits available / spent.

### User account 
```{r, paged.print = FALSE, eval=FALSE}
describe_account()
```

### File workspace

For the file space the data you will upload will oftentimes be areas of interests in JSON or SHP, some masks or scripts to use in user defined functions.

To get an overview about already uploaded files, you can use the already known `list_*` function. Here it is `list_files()`. If the workspace is empty, then it will say so.
```{r, eval=FALSE}
list_files()
```

As an example for the uploading, we will first temporarily download a GeoJSON file from the Github repository, upload it in a second step with `upload_file()` and then remove the temporary download file. As `target` parameter you can use also subfolders, in order to organize your workspace. If the subfolder does not exist, then it will be created during the upload.

```{r, eval=FALSE}
file = tempfile(fileext = ".json")
  
download.file(url = "https://raw.githubusercontent.com/Open-EO/openeo-r-client/master/examples/polygons.geojson", destfile = file)

openeo::upload_file(content=file,target="aoi/polygons.json")

file.remove(file)
```

Now, we call `list_files()` again, and as you can see, the file is now in the workspace under the given path.

```{r, eval=FALSE}
list_files()
```

The `download_file()` function works inverse to the upload and lets you retrieve the uploaded data.

```{r, eval=FALSE}
dl_file = download_file(src="aoi/polygons.json", dst = file)
```

```{r, eval=FALSE}
cat(readChar(dl_file,nchars = file.size(dl_file)))
```

The last function in this context is the `delete_file()` function, which removes a specific file from the workspace.

```{r, eval=FALSE}
delete_file(src = "aoi/polygons.json")
```

And again, the workspace is empty. (If not, then maybe other users may have left data on this demo account)

```{r, eval=FALSE}
list_files()
```

```{r, echo=FALSE, include=FALSE, eval=FALSE}
file.remove(dl_file)
rm(dl_file)
```


## Creating and storing of user-defined processes


The `ProcessCollection` is an object that offers the processes available by `list_processes()` as functions of an R6 object. Therefore all the parameter definitions and the process metadata are evaluated and translated into functions in R. To create the `ProcessCollection` just use `processes()` on an active openEO connection or specify one by making use of parameter `con`.

```{r, eval=FALSE}
p = processes()
```

Lets explore object `p` a bit further.

```{r, eval=FALSE}
class(p)
```

```{r, eval=FALSE}
names(p)
```

Here you can see all the available processes on the openEO service. The functions or fields under ".__enclos_env__", "clone" and "initialize" are R6 specific functions, but the rest are dynamically added functions. This means that when you connect to a different openEO service the functions here might be different or they have different parameter.

For comparison here are the processes listed in `list_processes()`:
```{r, eval=FALSE}
names(list_processes())
```

"load_collection" is a key function, because it is the point where the data is selected for further processsing. 

```{r, eval=FALSE}
class(p$load_collection)
```

```{r, eval=FALSE}
formals(p$load_collection)
```

You can see that there are 4 defined parameters. They are initialized with `NA`. More detailled information can be obtained by using the `describe_process()`. By typing in the different arguments and evaluating the function you receive a `ProcessNode` object, which are the building blocks of the process graph / workflow.

```{r, paged.print=FALSE, eval=FALSE}
describe_process(process = "load_collection")
```

### EVI Graph

In the following we will create the EVI calculation and store it as a process graph on the openEO service.

Most of the processes offered by openEO services are standardized, this means that it will be possible to use mathematical operators like `+`, `-` and alike coherently between different services. That also allowed us to overload the primitive mathematical operators in R so that it becomes easy to use.

The EVI calculation is an function that is going to be applied on specific bands in an optical image collection. It involves the bands "red", "blue" and the near infrared. This means that those 3 bands are computed into a single band, which will be referred to as reducing the band dimension. This calculation is a simple band arithmetic, which is usually done in R by passing a function to a raster calculation function like `raster::calc`. Similarly we use this mechanism in the openeo package.

```{r, eval=FALSE}
evi = function(data,context) {
  B08 = data[1]
  B04 = data[2]
  B02 = data[3]
  return((2.5 * (B08 - B04)) / sum(B08, 6 * B04, -7.5 * B02, 1))
}
```

The following coerce function will create an internal `Graph` object. Usually you won't need this explicit type cast, but in this case you can see the node and graph structure serialized as JSON object. Later use either the function itself or the resulting `ProcessNode` is passed to define a process graph.

```{r, eval=FALSE}
as(evi,"Graph")
```
The example before should demonstrate what would happen behind the scenes, that such a small code fragment for the band arithmetic translates into a more complex process graph. But usually you would not need to use that coerce function directly.

So, now we have created a small graph and we want to store it for later use at the openEO service.

```{r, paged.print=FALSE, eval=FALSE}
list_user_processes()
```
With the next command you can check your process graph locally for potential problems, before even sending it to the back-end.

```{r, eval=FALSE}
validate_process(graph = evi)
```

```{r, eval=FALSE}
graph_id = create_user_process(graph = evi, id = "evi", summary = "EVI calculation on an array with 3 bands", description = "The EVI calculation is based on an array of 3 band values: blue, red, nir. In that order.")
```

```{r, paged.print=FALSE, eval=FALSE}
list_user_processes()
```

Fetch the process graph definition as a user define openEO process and print it.

```{r, paged.print=FALSE, eval=FALSE}
evi_process = describe_user_process(id = "evi")
class(evi_process)
```

```{r, paged.print = FALSE, eval=FALSE}
evi_process
```

If you want the graph representation reimported into R, you can use `parse_graph` on this received `ProcessInfo` object or you can use the coerce function.

```{r, eval=FALSE}
evi_graph = parse_graph(json = evi_process) # or use as(evi_process,"Graph")
```


### Minimum EVI example

The prior use case covered a sub process graph. Now, we are going to create an analysis ready process graph that selects data, and makes multiple dimension modification. It will use the EVI band arithmetic as an inbound function.

We have used the variables `colls` and `formats` before. They originate from their respective list_* function.

```{r, eval=FALSE}
data = p$load_collection(id = colls$`COPERNICUS/S2`,
                             spatial_extent = list(
                               west=16.1,
                               east=16.6,
                               north=48.6,
                               south= 47.2
                             ),
                             temporal_extent = list(
                               "2018-04-01", "2018-05-01"
                             ),
                             bands=list("B8","B4","B2"))
```

Here we are using the EVI calculation as used in the previous example.
```{r, eval=FALSE}
spectral_reduce = p$reduce_dimension(data = data, dimension = "bands",reducer = function(data,context) {
  B08 = data[1]
  B04 = data[2]
  B02 = data[3]
  (2.5 * (B08 - B04)) / sum(B08, 6 * B04, -7.5 * B02, 1)
})
```


```{r, eval=FALSE}
temporal_reduce = p$reduce_dimension(data=spectral_reduce,dimension = "t", reducer = function(x,y){
  min(x)
})
```

As a "reducer" or "aggregator" function you will have to always create an anonymous function or use a predefined one, with the same amount of parameters. The naming of parameters does not matter, because simply the order matters. To know how to formulate the function, you need to check the back-end processes documentation, e.g. `process_viewer(p$reduce_dimension)` or `describe_process(p$reduce_dimension)`.

```{r, eval=FALSE}
apply_linear_transform = p$apply(data=temporal_reduce,process = function(value,...) {
  p$linear_scale_range(x = value, 
                           inputMin = -1, 
                           inputMax = 1, 
                           outputMin = 0, 
                           outputMax = 255)
})
```

As a last step we will store the results as a PNG file. The `ProcessNode` returned from that function will be our endnode in the graph and so we will pass it on towards openEO service functions.

```{r, eval=FALSE}
result = p$save_result(data=apply_linear_transform,format=formats$output$PNG)
```

```{r, eval=FALSE}
min_evi_graph_id = create_user_process( graph = result, id = "min_evi",summary="Minimum EVI calculation on Sentinel-2", description = "A preset process graph that will calculate the minimum NDVI on Sentinel-2 data, performs a linear scale into the value interval 0 to 255 in order to store the results as PNG.")
```

```{r, paged.print = FALSE, eval=FALSE}
list_user_processes()
```

Feel free to delete the example process again.

```{r, eval=FALSE}
delete_user_process(id = min_evi_graph_id)
```

### Integration of user defined processes

In the section "EVI Graph" we created and stored a sub graph that resembles the same code that was used as a reducer when creating the node 'spectral_reduce'. In an alternative approach we can load and reuse user defined processes. In analogy to the predefined processes of the openEO service we use `user_processes()` to create an easy-to-use ProcessNode builder.

```{r, eval=FALSE}
p = processes()
udps = user_processes()
colls = list_collections()
formats = list_file_formats()
```

```{r, eval=FALSE}
example_udp_node = udps$evi()

example_udp_node
```

```{r, eval=FALSE}
data = p$load_collection(id = colls$`COPERNICUS/S2`,
                             spatial_extent = list(
                               west=16.1,
                               east=16.6,
                               north=48.6,
                               south= 47.2
                             ),
                             temporal_extent = list(
                               "2018-04-01", "2018-05-01"
                             ),
                             bands=list("B8","B4","B2"))

spectral_reduce = p$reduce_dimension(data = data, dimension = "bands",reducer = function(data,context) {
  udps$evi(data = data)
})

temporal_reduce = p$reduce_dimension(data=spectral_reduce,dimension = "t", reducer = function(x,y){
  min(x)
})

apply_linear_transform = p$apply(data=temporal_reduce,process = function(value,...) {
  p$linear_scale_range(x = value, 
                           inputMin = -1, 
                           inputMax = 1, 
                           outputMin = 0, 
                           outputMax = 255)
})

result = p$save_result(data=apply_linear_transform,format=formats$output$PNG)

min_evi_graph = as(result,"Process")

```

Note that we reused our pre defined user process "evi" in the aggregation function, which shows that you can reuse your code in different contexts.

## Calculate immediate results

For development and testing you process graph you can use the `compute_result` function. Please keep in mind, that depending on the payment plan chosen or available at the openEO service, that there might be costs involved. Since it will block your command line until the calculations are done and the results are sent, choose a small data sample when using this function. It might also be the case that some provider won't allow UDF at this function. In cases where payments are involved you have the possibility to set the payment plan and the maximum amount of credits spent.

```{r, eval=FALSE}
# FIXME
temp = tempfile()
file = compute_result(graph = result, output_file = temp)
```

```{r, eval=FALSE}
r = raster::raster(file)
raster::spplot(r)
```


## Creating a job

- pass on the defined function, result node or graph

```{r, eval=FALSE}
job = create_job(graph=result,title = "Minimum EVI", description = "Minimum EVI calculation on Sentinel-2 data, including a linear scaling into 0 to 255 and exporting as PNG file.")
```

```{r, eval=FALSE}
jobs = list_jobs()
jobs
```

The job list is also printed as data.frame or tibble. But it is a list of job objects.

```{r, eval=FALSE}
class(jobs)
```

```{r, eval=FALSE}
job$id
```


```{r, eval=FALSE}
class(jobs[[job$id]])
```

```{r, eval=FALSE}
jobs[[job$id]]
```

Similarly as for the process graph `describe_job()` returns a more detailled description of the job.

```{r, eval=FALSE}
describe_job(job = job)
```

You can queue the job for execution by using `start_job()`

```{r, eval=FALSE}
start_job(job=job)
```

Now, we need to wait for the job to finish. We can get information on the status either by the job list or by the job meta data.

```{r, eval=FALSE}
list_jobs()
```

When it is finished, we can inspect the results.

```{r, paged.print=FALSE, eval=FALSE}
list_results(job=job)
```

In most cases we want to download the results.

```{r, eval=FALSE}
dir = tempdir()
download_results(job=job, folder = dir)
```

With the download function all result assets are downloaded into the target folder.

```{r, eval=FALSE}
list.files(dir)
```

```{r, eval=FALSE}
delete_job(job=job)
```


## Creating a service

```{r, eval=FALSE}
service_types = list_service_types()
```


```{r, eval=FALSE}
test_service = create_service(type = service_types$xyz, graph = result, title = "XYZ service for minimum EVI", description = "XYZ service for minimum EVI from the getting_started guide.",enabled = TRUE)
```

```{r, eval=FALSE}
list_services()
```

```{r, eval=FALSE}
describe_service(service = test_service)
```

```{r, eval=FALSE}
library(magrittr)
library(leaflet)
leaflet() %>% addTiles() %>% addTiles(test_service$url, tileOptions(tms=TRUE)) %>% setView(lng = 16.363449,lat=48.210033,zoom = 7)
```

## RStudio specific features

In this web page representation certain features cannot be shown, but shall be mentioned, for you to try out in RStudio.

- `process_viewer()`: opens the Viewer panel and renders the process information as HTML webpage
- `collection_viewer()`: similar to `process_viewer()`, but for collections
- `terms_of_service()`: also a web view of the terms of service
- `privacy_policy`: web view of the privacy policy
- connection contract implementation: creates a connection in the connections pane for the openEO service